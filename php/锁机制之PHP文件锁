锁机制之所以存在是因为并发导致的资源竞争，为了确保操作的有效性和完整性，可以通过锁机制将并发状态转换成串行状态。作为锁机制中的一种，PHP的文件锁也是为了应对资源竞争。假设一个应用场景，在存在较大并发的情况下，通过fwrite向文件尾部多次有序的写入数据，不加锁的情况下会发生什么？多次有序的写入操作相当于一个事务，我们此时需要保证这个事务的完整性。
如下代码简单模拟了这种事务并发状态： process1.php

<?php
$num = 100;
$filename = "processdata.txt";

$fp = fopen($filename, "a");
for ($i = 0; $i < $num; $i++) {
&nbsp; &nbsp; fwrite($fp, "process1: " . $i . "\r\n");
&nbsp; &nbsp; usleep(100000);
}
fclose($fp);

我们需要先执行第一个事务，在processdata.txt文件中写入这100行。
process2.php
<?php
$num = 100;
$filename = "processdata.txt";

$fp = fopen($filename, "a");
for ($i = 0; $i < $num; $i++) {
&nbsp; &nbsp; fwrite($fp, "process2: " . $i . "\r\n");
&nbsp; &nbsp; usleep(100000);
}
fclose($fp);

第二个事务，继续向processdata.txt文件中写入100行。
多次同时执行，虽然都写了100行，但是事务1和事务2的数据交错写入，这并不是我们想要的结果。我们要的是事务完整的执行，此时我们需要有个机制去保证在第一个事务执行完后再执行第二个。在PHP中，flock函数完成了这一使命。在事物1和事务2的循环前面都加上： flock($fp, LOCK_EX); 就能满足我们的需求，将两个事务串行。
当某一个事务执行完flock时，因为我们在这里添加的是LOCK_EX（独占锁定），所以所有对资源的操作都会被阻塞，只有当事务执行完成后，后面的事务才会执行。我们可以通过输出当前的时间的方法来确认这一点。
关于在尾部追加写入，在unix系统的早期版本中存在一个并发写入的问题，如果要在尾部追加，需要先lseek位置，再write。当多个进程同时操作时，会因为并发导致的覆盖写入的问题，即两个进程同时获取尾部的偏移后，先后执行write操作，后面的操作会将前面的操作覆盖。这个问题在后面以添加打开时的O_APPEND操作而得到解决，它将查找和写入操作变成了一个原子操作。
在PHP的fopen函数的实现中，如果我们使用a参数在文件的尾部追加内容，其调用open函数中oflag参数为 O_CREAT|O_APPEND，即我们使用追加操作不用担心并发追加写入的问题。
在PHP的session默认存储实现中也用到了flock文件锁，当session开始时就调用PS_READ_FUNC，且以O_CREAT | O_RDWR | O_BINARY 打开session数据文件，此时会调用flock加上写锁，如果此时有其它进程访问此文件（即同一用户再次发起对当前文件的请求），就会显示页面加载中，进程被阻塞了。加写锁其出发点是为了保证此次会话中对session的操作事务能完整的执行，防止其它进程的干扰，保证数据的一致性。如果一个页面没有session修改操作，可以尽早的调用session_write_close()释放锁。
文件锁是针对文件的锁，除了这种释义，还可以理解为用文件作为锁。在实际工作中，有时为确保单个进程的执行，我们会在程序执行前判断文件是否存在，如果不存在则创建一个空文件，在进程结束后删除这个空文件，如果存在，则不执行。
